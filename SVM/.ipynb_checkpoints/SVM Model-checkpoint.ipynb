{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename, has_y):\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "    # Slice off first line which is the list of words\n",
    "    data = data[1:]\n",
    "    # Split the string on each line into ints and convert to numpy array\n",
    "    data = np.array([[int(x) for x in line.split(\" \")] for line in data], dtype=\"float64\")\n",
    "    \n",
    "    if has_y:\n",
    "        # y is the first column while X is everything else\n",
    "        X = data[:, 1:]\n",
    "        y = data[:, 0]\n",
    "\n",
    "        return X, y\n",
    "    else:\n",
    "        return data\n",
    "    \n",
    "def grid_summary(grid):\n",
    "    print(\"Best parameters set found on development set:\\n\")\n",
    "    print(grid.best_params_)\n",
    "    print(\"Best CV score: \", grid.best_score_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\\n\")\n",
    "\n",
    "    means = grid.cv_results_['mean_test_score']\n",
    "    stds = grid.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "\n",
    "X_train, y_train = read_data(\"training_data.txt\", has_y=True)\n",
    "X_test = read_data(\"test_data.txt\", has_y=False)\n",
    "\n",
    "# Shuffle the order of the training data just in case\n",
    "X_train, y_train = sklearn.utils.shuffle(X_train, y_train)\n",
    "# Make a smaller dataset with only 10% the size\n",
    "X_train10 = X_train[:len(X_train)//10]\n",
    "y_train10 = y_train[:len(y_train)//10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preliminary trial on full dataset\n",
    "# svc = SVC()\n",
    "# svc.fit(X_train, y_train)\n",
    "# svc.score(X_train, y_train)\n",
    "# >>> 0.84655\n",
    "# svc.support_.shape\n",
    "# >>> (1285,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(preprocessing.StandardScaler(), SVC(kernel=\"linear\"))\n",
    "# grid = GridSearchCV(pipe, return_train_score=True, verbose=1,\n",
    "#                     cv=3, \n",
    "#                     param_grid={\"svc__C\":[2.0, 4.0, 6.0], \"svc__gamma\":[0.0002, 0.0004, 0.0006]}, \n",
    "#                     n_jobs=4)\n",
    "        \n",
    "grid = GridSearchCV(pipe, return_train_score=True, verbose=1,\n",
    "                    cv=5, \n",
    "                    param_grid={\"svc__C\":[0.0001, 0.0003, 0.001, 0.003]}, \n",
    "                    n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:   49.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'svc__C': 0.0003}\n",
      "Best CV score:  0.797\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.782 (+/-0.044) for {'svc__C': 0.0001}\n",
      "0.797 (+/-0.028) for {'svc__C': 0.0003}\n",
      "0.794 (+/-0.031) for {'svc__C': 0.001}\n",
      "0.775 (+/-0.035) for {'svc__C': 0.003}\n"
     ]
    }
   ],
   "source": [
    "# As a test just fit on 10% to check parameter values to use \n",
    "grid.fit(X_train10, y_train10)\n",
    "grid_summary(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8955\n",
      "0.81395\n"
     ]
    }
   ],
   "source": [
    "# Use the model trained on 10% to check on 100%\n",
    "print(grid.score(X_train10, y_train10))\n",
    "print(grid.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 49.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'svc__C': 0.0003}\n",
      "Best CV score:  0.8487\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.842 (+/-0.007) for {'svc__C': 0.0001}\n",
      "0.849 (+/-0.003) for {'svc__C': 0.0003}\n",
      "0.849 (+/-0.008) for {'svc__C': 0.001}\n",
      "0.845 (+/-0.007) for {'svc__C': 0.003}\n"
     ]
    }
   ],
   "source": [
    "# Use the restricted parameter range to search on the actual data set\n",
    "grid.fit(X_train, y_train)\n",
    "grid_summary(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8718\n"
     ]
    }
   ],
   "source": [
    "# Check the training score in comparison with the CV score above\n",
    "print(grid.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"out3.txt\", \"w\") as f:\n",
    "    f.write(\"Id,Prediction\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        f.write(\"{0},{1}\\n\".format(i+1, pred[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

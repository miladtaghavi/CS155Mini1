{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename, has_y):\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "    # Slice off first line which is the list of words\n",
    "    data = data[1:]\n",
    "    # Split the string on each line into ints and convert to numpy array\n",
    "    data = np.array([[int(x) for x in line.split(\" \")] for line in data], dtype=\"float64\")\n",
    "    \n",
    "    if has_y:\n",
    "        # y is the first column while X is everything else\n",
    "        X = data[:, 1:]\n",
    "        y = data[:, 0]\n",
    "\n",
    "        return X, y\n",
    "    else:\n",
    "        return data\n",
    "    \n",
    "def grid_summary(grid):\n",
    "    print(\"Best parameters set found on development set:\\n\")\n",
    "    print(grid.best_params_)\n",
    "    print(\"Best CV score: \", grid.best_score_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\\n\")\n",
    "\n",
    "    means = grid.cv_results_['mean_test_score']\n",
    "    stds = grid.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "\n",
    "X_train, y_train = read_data(\"training_data.txt\", has_y=True)\n",
    "X_test = read_data(\"test_data.txt\", has_y=False)\n",
    "\n",
    "# Shuffle the order of the training data just in case\n",
    "X_train, y_train = sklearn.utils.shuffle(X_train, y_train)\n",
    "# Make a smaller dataset with only 10% the size\n",
    "X_train10 = X_train[:len(X_train)//10]\n",
    "y_train10 = y_train[:len(y_train)//10]\n",
    "X_train20 = X_train[:len(X_train)//5]\n",
    "y_train20 = y_train[:len(y_train)//5]\n",
    "\n",
    "# X_train = scipy.sparse.csr_matrix(X_train)\n",
    "# X_test  = scipy.sparse.csr_matrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78925\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=4)\n",
    "SVCTop = SVC(C=4.0, gamma=0.0002)\n",
    "norm = preprocessing.StandardScaler()\n",
    "# pca = PCA(n_components=200)\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, learning_rate=1)\n",
    "\n",
    "cv = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train10, y_train10):\n",
    "    X_train2, X_cv = X_train10[train_index], X_train10[test_index]\n",
    "    y_train2, y_cv = y_train10[train_index], y_train10[test_index]\n",
    "    \n",
    "    # Preprocessing - Norm, PCA, fit SVC and subtract its predictions\n",
    "    X_train2 = norm.fit_transform(X_train2)\n",
    "#     X_train2 = pca.fit_transform(X_train2)\n",
    "#     SVCTop.fit(X_train2, y_train2)\n",
    "#     SVCTop_pred = SVCTop.predict(X_train2)\n",
    "    y_train2_res = y_train2 #- SVCTop_pred\n",
    "    \n",
    "    # Fit the residues to a Adaboost\n",
    "    ada.fit(X_train2, y_train2_res)\n",
    "    \n",
    "    # CV set. Same preprocessing\n",
    "    # Norm, PCA, use the fitted SVC as a baseline prediction\n",
    "    X_cv = norm.transform(X_cv)\n",
    "#     X_cv = pca.transform(X_cv)\n",
    "    y_pred = 0#SVCTop.predict(X_cv)\n",
    "    \n",
    "    # Add the predictions from the adaboost to y_pred\n",
    "    y_pred += ada.predict(X_cv)\n",
    "    \n",
    "    cv.append(accuracy_score(y_pred, y_cv))\n",
    "    \n",
    "print(np.mean(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:   52.6s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  24 | elapsed:   52.9s remaining:   10.5s\n",
      "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'adaboostclassifier__n_estimators': 300}\n",
      "Best CV score:  0.7915\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.599 (+/-0.009) for {'adaboostclassifier__n_estimators': 1}\n",
      "0.699 (+/-0.024) for {'adaboostclassifier__n_estimators': 10}\n",
      "0.753 (+/-0.017) for {'adaboostclassifier__n_estimators': 30}\n",
      "0.789 (+/-0.030) for {'adaboostclassifier__n_estimators': 100}\n",
      "0.791 (+/-0.012) for {'adaboostclassifier__n_estimators': 300}\n",
      "0.780 (+/-0.007) for {'adaboostclassifier__n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(preprocessing.StandardScaler(), \n",
    "                     AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), \n",
    "                                        learning_rate=1))\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid={\"adaboostclassifier__n_estimators\":[1, 10, 30, 100, 300, 1000]}, n_jobs=4, cv=4, verbose=10)\n",
    "grid.fit(X_train10, y_train10)\n",
    "grid_summary(grid)\n",
    "\n",
    "# Using 20%!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  24 | elapsed:   24.9s remaining:    4.9s\n",
      "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'adaboostclassifier__n_estimators': 1000}\n",
      "Best CV score:  0.7755\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.568 (+/-0.029) for {'adaboostclassifier__n_estimators': 1}\n",
      "0.685 (+/-0.061) for {'adaboostclassifier__n_estimators': 10}\n",
      "0.736 (+/-0.024) for {'adaboostclassifier__n_estimators': 30}\n",
      "0.764 (+/-0.049) for {'adaboostclassifier__n_estimators': 100}\n",
      "0.763 (+/-0.035) for {'adaboostclassifier__n_estimators': 300}\n",
      "0.775 (+/-0.032) for {'adaboostclassifier__n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(preprocessing.StandardScaler(), \n",
    "                     AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), \n",
    "                                        learning_rate=1))\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid={\"adaboostclassifier__n_estimators\":[1, 10, 30, 100, 300, 1000]}, n_jobs=4, cv=4, verbose=10)\n",
    "grid.fit(X_train10, y_train10)\n",
    "grid_summary(grid)\n",
    "\n",
    "# Using 10%!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=4)]: Done   7 out of  12 | elapsed:   12.6s remaining:    9.0s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of  12 | elapsed:   30.8s remaining:   10.2s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed:   31.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'adaboostclassifier__n_estimators': 30}\n",
      "Best CV score:  0.774\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.600 (+/-0.007) for {'adaboostclassifier__n_estimators': 1}\n",
      "0.706 (+/-0.013) for {'adaboostclassifier__n_estimators': 10}\n",
      "0.774 (+/-0.011) for {'adaboostclassifier__n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(preprocessing.StandardScaler(), \n",
    "                     AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1))\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid={\"adaboostclassifier__n_estimators\":[1, 10, 30]},\n",
    "                    n_jobs=4, cv=4, verbose=10)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid_summary(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=4)]: Done   7 out of  12 | elapsed:  3.8min remaining:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done   9 out of  12 | elapsed: 13.6min remaining:  4.5min\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  12 | elapsed: 13.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'adaboostclassifier__n_estimators': 300}\n",
      "Best CV score:  0.83055\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.816 (+/-0.012) for {'adaboostclassifier__n_estimators': 100}\n",
      "0.831 (+/-0.009) for {'adaboostclassifier__n_estimators': 300}\n",
      "0.830 (+/-0.013) for {'adaboostclassifier__n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(preprocessing.StandardScaler(), \n",
    "                     AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), learning_rate=1))\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid={\"adaboostclassifier__n_estimators\":[100, 300, 1000]},\n",
    "                    n_jobs=4, cv=4, verbose=10)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid_summary(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  24 | elapsed:  7.8min remaining:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed: 24.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'adaboostclassifier__n_estimators': 300}\n",
      "Best CV score:  0.8247\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.604 (+/-0.008) for {'adaboostclassifier__n_estimators': 1}\n",
      "0.741 (+/-0.024) for {'adaboostclassifier__n_estimators': 10}\n",
      "0.797 (+/-0.006) for {'adaboostclassifier__n_estimators': 30}\n",
      "0.822 (+/-0.015) for {'adaboostclassifier__n_estimators': 100}\n",
      "0.825 (+/-0.011) for {'adaboostclassifier__n_estimators': 300}\n",
      "0.808 (+/-0.008) for {'adaboostclassifier__n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(preprocessing.StandardScaler(),\n",
    "                     AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2), \n",
    "                                        learning_rate=1))\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid={\"adaboostclassifier__n_estimators\":[1, 10, 30, 100, 300, 1000]}, n_jobs=4, cv=4, verbose=10)\n",
    "grid.fit(X_train, y_train)\n",
    "grid_summary(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('adaboostclassifier', AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "  ...one,\n",
       "            splitter='best'),\n",
       "          learning_rate=1, n_estimators=300, random_state=None))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the best adaboost classifier above to fit full data\n",
    "pipe = make_pipeline(preprocessing.StandardScaler(), \n",
    "                     AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), \n",
    "                                        n_estimators=300, learning_rate=1))\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85355\n"
     ]
    }
   ],
   "source": [
    "# Check the training score\n",
    "print(pipe.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"out6.txt\", \"w\") as f:\n",
    "    f.write(\"Id,Prediction\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        f.write(\"{0},{1}\\n\".format(i+1, int(pred[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS155 Miniproject 1\n",
    "\n",
    "zchen@caltech.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis via Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final validation data set\n",
    "FV_data = np.loadtxt('./test_data.txt',delimiter=' ',skiprows=1)\n",
    "# Load input training data set\n",
    "train_data = np.loadtxt('./training_data.txt',delimiter=' ',skiprows=1)\n",
    "\n",
    "# extract y_train and x_train from training set\n",
    "y_tall = train_data[:,0]\n",
    "x_tall = train_data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode categories\n",
    "y_tall = keras.utils.np_utils.to_categorical(y_tall)\n",
    "\n",
    "# Split the training data k-fold number of ways for k-fold validation of the learning algorithm\n",
    "kf = sklearn.model_selection.KFold(n_splits=5)\n",
    "inds = [ind for ind in kf.split(x_tall, y_tall)]\n",
    "\n",
    "# Returns indices for validation and training splits\n",
    "train,val = inds[0]\n",
    "Xtrain = x_tall[train]\n",
    "Ytrain = y_tall[train]\n",
    "Xval = x_tall[val]\n",
    "Yval = y_tall[val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Neural Networks on bag of words dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 5)                 255       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 106,037\n",
      "Trainable params: 105,727\n",
      "Non-trainable params: 310\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Function to generate DNN of given depth and width\n",
    "def getModel(layers):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layers[0],input_shape=(1000,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    for i in layers[1:]:\n",
    "        model.add(Dense(i))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    # Once you one-hot encode the data labels, the line below should be \n",
    "    # predicting probabilities of each of the 2 classes\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "# Model for problem 2C, create DNN with less than 100 hidden layers layers\n",
    "model = getModel([100,50,5])\n",
    "# Printing a summary of the layers and weights in your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 99us/step - loss: 0.1932 - acc: 0.9530 - val_loss: 0.4825 - val_acc: 0.8105\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 1s 45us/step - loss: 0.1355 - acc: 0.9731 - val_loss: 0.5418 - val_acc: 0.8002\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 1s 46us/step - loss: 0.0959 - acc: 0.9822 - val_loss: 0.4827 - val_acc: 0.8125\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 1s 46us/step - loss: 0.0658 - acc: 0.9876 - val_loss: 0.5146 - val_acc: 0.8087\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 1s 46us/step - loss: 0.0448 - acc: 0.9929 - val_loss: 0.5272 - val_acc: 0.8100\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 1s 46us/step - loss: 0.0295 - acc: 0.9956 - val_loss: 0.6486 - val_acc: 0.8055\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 1s 46us/step - loss: 0.0194 - acc: 0.9968 - val_loss: 0.6681 - val_acc: 0.8020\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 1s 51us/step - loss: 0.0143 - acc: 0.9981 - val_loss: 0.7081 - val_acc: 0.8083\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 1s 52us/step - loss: 0.0097 - acc: 0.9989 - val_loss: 1.0159 - val_acc: 0.7910\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 1s 47us/step - loss: 0.0082 - acc: 0.9986 - val_loss: 0.8282 - val_acc: 0.8055\n"
     ]
    }
   ],
   "source": [
    "# Compile the DNN model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='RMSprop', metrics=['accuracy'])\n",
    "fit = model.fit(Xtrain, Ytrain, batch_size=2**8, epochs=10,verbose=1,validation_data=(Xval, Yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss and validation accuracy vs the number of weak decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('Training error',model.evaluate(x=x_test, y=y_test))\n",
    "print('Test error',SK_AdaBoost.score(Xval, Yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy plateaus at 82%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

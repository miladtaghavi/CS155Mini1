{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS155 Miniproject 1\n",
    "\n",
    "zchen@caltech.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis via Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final validation data set\n",
    "FV_data = np.loadtxt('../data/test_data.txt',delimiter=' ',skiprows=1)\n",
    "# Load input training data set\n",
    "train_data = np.loadtxt('../data/training_data.txt',delimiter=' ',skiprows=1)\n",
    "utrain_data = np.unique(train_data,axis=0)\n",
    "\n",
    "# Get header words list\n",
    "f = open('../data/test_data.txt','r')\n",
    "words = np.array(f.readline().split())\n",
    "f.close()\n",
    "\n",
    "# Splot y_train and x_train from training set\n",
    "x_tall = train_data[:,1:]\n",
    "y_tall = train_data[:,0]\n",
    "\n",
    "x_uall = utrain_data[:,1:]\n",
    "y_uall = utrain_data[:,0]\n",
    "\n",
    "# One hot encode categories\n",
    "y_tall = keras.utils.np_utils.to_categorical(y_tall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions for Neural network debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate DNN of given depth and width\n",
    "def getModel(layers,Pdrop):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layers[0],input_shape=(1000,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(Pdrop))\n",
    "    for i in layers[1:]:\n",
    "        model.add(Dense(i))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "    \n",
    "    # predicting probabilities of each of the 2 classes\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "# undo one hot encoding\n",
    "def Unencode(out):\n",
    "    ypred = out[:,0] < out[:,1]\n",
    "    return ypred\n",
    "\n",
    "# Function to get explicit model accuracy from softmax\n",
    "def getAccuracy(model,xt,yt):\n",
    "    out = model.predict(xt)\n",
    "    ypred = Unencode(out)\n",
    "    ytrue = Unencode(yt)\n",
    "    acc = 1.0*np.sum(ypred == ytrue)/len(ytrue)\n",
    "    return acc\n",
    "\n",
    "# Function to get bag of words which were misclassified\n",
    "def getBagOfWords(xtrain,ypred,ytrue,words):\n",
    "    out = []\n",
    "    ypredu = Unencode(ypred).astype(int)\n",
    "    ytrueu = Unencode(ytrue).astype(int)\n",
    "    # Get locations of bag of words which were misclassified\n",
    "    idx = np.arange(0,len(ypredu))\n",
    "    idxErr = idx[ypredu!=ytrueu]\n",
    "    Xerr = xtrain[ypredu!=ytrueu]\n",
    "    j = 0\n",
    "    for i in Xerr:\n",
    "        out.append([ytrue[idxErr[j]],ypred[idxErr[j]],words[i>0],i[i>0]])\n",
    "        j=j+1\n",
    "    return out\n",
    "\n",
    "# Function to write final predictions\n",
    "def writeResults(ypred):\n",
    "    f = open('DNN_submission.txt','w')\n",
    "    f.write('Id,Prediction\\n')\n",
    "    for i in range(0,len(ypred)):\n",
    "        f.write(str(i+1)+','+str(int(ypred[i]))+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Neural network model for bag of words predictor\n",
    "\n",
    "Initial testing of single DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/4\n",
      "16000/16000 [==============================] - 9s 590us/step - loss: 0.4957 - acc: 0.7658 - val_loss: 0.3615 - val_acc: 0.8400\n",
      "Epoch 2/4\n",
      "16000/16000 [==============================] - 3s 206us/step - loss: 0.3180 - acc: 0.8627 - val_loss: 0.3440 - val_acc: 0.8553\n",
      "Epoch 3/4\n",
      "16000/16000 [==============================] - 3s 193us/step - loss: 0.2556 - acc: 0.8916 - val_loss: 0.3716 - val_acc: 0.8562\n",
      "Epoch 4/4\n",
      "16000/16000 [==============================] - 3s 173us/step - loss: 0.2084 - acc: 0.9160 - val_loss: 0.3898 - val_acc: 0.8507\n",
      "4000/4000 [==============================] - 2s 526us/step\n"
     ]
    }
   ],
   "source": [
    "# Split the training data k-fold number of ways for k-fold validation of the learning algorithm\n",
    "k=5\n",
    "kf = sklearn.model_selection.KFold(n_splits=k)\n",
    "inds = [ind for ind in kf.split(x_tall, y_tall)]\n",
    "\n",
    "i=0\n",
    "train,val = inds[0]\n",
    "# Training and validation data for k fold cross validation\n",
    "Xtrain = x_tall[train]\n",
    "Ytrain = y_tall[train]\n",
    "Xval = x_tall[val]\n",
    "Yval = y_tall[val]\n",
    "\n",
    "# Define the DNN model\n",
    "model = getModel([500,250,125],0.4)\n",
    "\n",
    "# Compile it and fit\n",
    "model.compile(loss='categorical_crossentropy',optimizer='RMSprop', metrics=['accuracy'])\n",
    "model.fit(Xtrain, Ytrain, batch_size=2**8, epochs=4,verbose=1,validation_data=(Xval, Yval))\n",
    "ypred = model.predict(Xval,batch_size=2**8,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 1.]), array([0.6994479 , 0.30055207], dtype=float32), array(['thi', 'veri', 'get', 'onli', 'look', 'want', 'see', 'mani', 'new',\n",
      "       'peopl', 'still', 'need', 'two', 'feel', 'start', 'long', 'listen',\n",
      "       'excel', 'enough', 'person', 'cover', 'almost', 'scene', 'instead',\n",
      "       'famili', 'sever', 'hour', 'els', 'fine', 'talk', 'american',\n",
      "       'entir', 'lack', 'impress', 'state', 'avail', 'certainli',\n",
      "       'student', 'danc', 'parent', 'critic', 'centuri', 'train',\n",
      "       'aspect'], dtype='<U12'), array([3., 2., 1., 1., 2., 1., 2., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1.,\n",
      "       1., 1., 2., 2., 6., 1., 1., 1., 1., 1.])]\n"
     ]
    }
   ],
   "source": [
    "# Debugging bag of words\n",
    "out = getBagOfWords(Xval,ypred,Yval,words)\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method  validation for single DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the DNN model\n",
    "def getDNNCross(k,x_tall,y_tall):\n",
    "    # Storage for k fold cross validation    \n",
    "    trainErr = []\n",
    "    testErr = []\n",
    "    acc = []\n",
    "    \n",
    "    # Split the training data k-fold number of ways for k-fold validation of the learning algorithm\n",
    "    kf = sklearn.model_selection.KFold(n_splits=k)\n",
    "    inds = [ind for ind in kf.split(x_tall, y_tall)]\n",
    "    \n",
    "    i=0\n",
    "    for train,val in inds:\n",
    "        # Training and validation data for k fold cross validation\n",
    "        Xtrain = x_tall[train]\n",
    "        Ytrain = y_tall[train]\n",
    "        Xval = x_tall[val]\n",
    "        Yval = y_tall[val]\n",
    "    \n",
    "        # Define the DNN model\n",
    "        model = getModel([500,250,125],0.4)\n",
    "        \n",
    "        # Compile it and fit\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='RMSprop', metrics=['accuracy'])\n",
    "        model.fit(Xtrain, Ytrain, batch_size=2**8, epochs=10,verbose=1,validation_data=(Xval, Yval))\n",
    "        \n",
    "        # store training and test error\n",
    "        trainErr.append(model.evaluate(x=Xtrain, y=Ytrain))\n",
    "        testErr.append(model.evaluate(x=Xval, y=Yval))\n",
    "        acc.append(getAccuracy(model,Xval,Yval))\n",
    "\n",
    "        # Status output\n",
    "        print('k-iteration = ',i)\n",
    "        i=i+1\n",
    "        trainErr = np.array(trainErr)\n",
    "        testErr = np.array(testErr)\n",
    "        \n",
    "    print('\\n trainErr')\n",
    "    print(trainErr)\n",
    "    print('avg trainErr',np.mean(trainErr,axis=0))\n",
    "    print('\\n testErr')\n",
    "    print(testErr)\n",
    "    print('avg testErr',np.mean(testErr,axis=0))\n",
    "    print('\\n Accuracy')\n",
    "    print(acc)\n",
    "    print('avg acc',np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 14s 904us/step - loss: 0.4877 - acc: 0.7672 - val_loss: 0.3531 - val_acc: 0.8415\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 4s 232us/step - loss: 0.3224 - acc: 0.8587 - val_loss: 0.3569 - val_acc: 0.8460\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 3s 188us/step - loss: 0.2588 - acc: 0.8908 - val_loss: 0.3846 - val_acc: 0.8503\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 3s 183us/step - loss: 0.2115 - acc: 0.9119 - val_loss: 0.3895 - val_acc: 0.8470\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 3s 180us/step - loss: 0.1695 - acc: 0.9320 - val_loss: 0.4384 - val_acc: 0.8445\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 3s 202us/step - loss: 0.1379 - acc: 0.9449 - val_loss: 0.4329 - val_acc: 0.8460\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 3s 185us/step - loss: 0.1075 - acc: 0.9587 - val_loss: 0.5665 - val_acc: 0.8377\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 3s 180us/step - loss: 0.0931 - acc: 0.9644 - val_loss: 0.5285 - val_acc: 0.8445\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 3s 179us/step - loss: 0.0758 - acc: 0.9719 - val_loss: 0.6146 - val_acc: 0.8365\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 3s 180us/step - loss: 0.0579 - acc: 0.9787 - val_loss: 0.6198 - val_acc: 0.8437\n",
      "16000/16000 [==============================] - 4s 256us/step\n",
      "4000/4000 [==============================] - 1s 256us/step\n",
      "k-iteration =  0\n",
      "\n",
      " trainErr\n",
      "[[0.00926458 0.99825   ]]\n",
      "avg trainErr [0.00926458 0.99825   ]\n",
      "\n",
      " testErr\n",
      "[[0.61978289 0.84375   ]]\n",
      "avg testErr [0.61978289 0.84375   ]\n",
      "\n",
      " Accuracy\n",
      "[0.84375]\n",
      "avg acc 0.84375\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 16s 973us/step - loss: 0.4783 - acc: 0.7747 - val_loss: 0.3648 - val_acc: 0.8418\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 3s 195us/step - loss: 0.3192 - acc: 0.8616 - val_loss: 0.3585 - val_acc: 0.8495\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 3s 193us/step - loss: 0.2589 - acc: 0.8905 - val_loss: 0.3907 - val_acc: 0.8380\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 3s 179us/step - loss: 0.2114 - acc: 0.9136 - val_loss: 0.4053 - val_acc: 0.8490\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 3s 178us/step - loss: 0.1689 - acc: 0.9334 - val_loss: 0.4234 - val_acc: 0.8480\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 3s 182us/step - loss: 0.1374 - acc: 0.9461 - val_loss: 0.4857 - val_acc: 0.8430\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 3s 192us/step - loss: 0.1092 - acc: 0.9585 - val_loss: 0.5122 - val_acc: 0.8470\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 3s 204us/step - loss: 0.0884 - acc: 0.9671 - val_loss: 0.5473 - val_acc: 0.8468\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 3s 195us/step - loss: 0.0728 - acc: 0.9729 - val_loss: 0.6542 - val_acc: 0.8260\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 3s 207us/step - loss: 0.0617 - acc: 0.9769 - val_loss: 0.6305 - val_acc: 0.8463\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-45e6099be49c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetDNNCross\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_tall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-137-ef74a8c5f060>\u001b[0m in \u001b[0;36mgetDNNCross\u001b[0;34m(k, x_tall, y_tall)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# store training and test error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtrainErr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mtestErr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "getDNNCross(5,x_tall,y_tall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Random Forest of weakly trained Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DNN  0\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 9s 544us/step - loss: 0.4455 - acc: 0.7926\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 150us/step - loss: 0.1828 - acc: 0.9326\n",
      "16000/16000 [==============================] - 6s 357us/step\n",
      "4000/4000 [==============================] - 1s 196us/step\n",
      "Training DNN  1\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 9s 565us/step - loss: 0.4401 - acc: 0.8002\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 145us/step - loss: 0.1759 - acc: 0.9351\n",
      "16000/16000 [==============================] - 6s 358us/step\n",
      "4000/4000 [==============================] - 1s 195us/step\n",
      "Training DNN  2\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 595us/step - loss: 0.4449 - acc: 0.7946\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 151us/step - loss: 0.1723 - acc: 0.9356\n",
      "16000/16000 [==============================] - 6s 391us/step\n",
      "4000/4000 [==============================] - 1s 247us/step\n",
      "Training DNN  3\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 9s 575us/step - loss: 0.4316 - acc: 0.7963\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 159us/step - loss: 0.1835 - acc: 0.9314\n",
      "16000/16000 [==============================] - 6s 399us/step\n",
      "4000/4000 [==============================] - 1s 217us/step\n",
      "Training DNN  4\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 614us/step - loss: 0.4365 - acc: 0.7992\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 176us/step - loss: 0.1815 - acc: 0.9322\n",
      "16000/16000 [==============================] - 6s 405us/step\n",
      "4000/4000 [==============================] - 1s 232us/step\n",
      "Training DNN  5\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 739us/step - loss: 0.4339 - acc: 0.8021\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 152us/step - loss: 0.1767 - acc: 0.9353\n",
      "16000/16000 [==============================] - 7s 439us/step\n",
      "4000/4000 [==============================] - 1s 231us/step\n",
      "Training DNN  6\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 603us/step - loss: 0.4395 - acc: 0.7990\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 172us/step - loss: 0.1782 - acc: 0.9352\n",
      "16000/16000 [==============================] - 7s 429us/step\n",
      "4000/4000 [==============================] - 1s 225us/step\n",
      "Training DNN  7\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 606us/step - loss: 0.4328 - acc: 0.7973\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 154us/step - loss: 0.1827 - acc: 0.9313\n",
      "16000/16000 [==============================] - 7s 423us/step\n",
      "4000/4000 [==============================] - 1s 226us/step\n",
      "Training DNN  8\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 603us/step - loss: 0.4527 - acc: 0.7883\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 155us/step - loss: 0.1641 - acc: 0.9403\n",
      "16000/16000 [==============================] - 7s 424us/step\n",
      "4000/4000 [==============================] - 1s 237us/step\n",
      "Training DNN  9\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 627us/step - loss: 0.4314 - acc: 0.8036\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 158us/step - loss: 0.1800 - acc: 0.9318\n",
      "16000/16000 [==============================] - 7s 408us/step\n",
      "4000/4000 [==============================] - 1s 236us/step\n",
      "Training DNN  10\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 595us/step - loss: 0.4403 - acc: 0.7953\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 158us/step - loss: 0.1706 - acc: 0.9377\n",
      "16000/16000 [==============================] - 7s 414us/step\n",
      "4000/4000 [==============================] - 1s 231us/step\n",
      "Training DNN  11\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 614us/step - loss: 0.4422 - acc: 0.7956\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 164us/step - loss: 0.1817 - acc: 0.9321\n",
      "16000/16000 [==============================] - 7s 429us/step\n",
      "4000/4000 [==============================] - 1s 244us/step\n",
      "Training DNN  12\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 632us/step - loss: 0.4395 - acc: 0.7963\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 151us/step - loss: 0.1763 - acc: 0.9337\n",
      "16000/16000 [==============================] - 7s 432us/step\n",
      "4000/4000 [==============================] - 1s 245us/step\n",
      "Training DNN  13\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 621us/step - loss: 0.4435 - acc: 0.7946\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 154us/step - loss: 0.1741 - acc: 0.9356\n",
      "16000/16000 [==============================] - 7s 416us/step\n",
      "4000/4000 [==============================] - 1s 251us/step\n",
      "Training DNN  14\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 635us/step - loss: 0.4399 - acc: 0.7995\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 174us/step - loss: 0.1749 - acc: 0.9349\n",
      "16000/16000 [==============================] - 7s 439us/step\n",
      "4000/4000 [==============================] - 1s 241us/step\n",
      "Training DNN  15\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 11s 698us/step - loss: 0.4316 - acc: 0.8021\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 164us/step - loss: 0.1791 - acc: 0.9331\n",
      "16000/16000 [==============================] - 7s 428us/step\n",
      "4000/4000 [==============================] - 1s 231us/step\n",
      "Training DNN  16\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 637us/step - loss: 0.4590 - acc: 0.7927\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 166us/step - loss: 0.1729 - acc: 0.9374 0s - loss: 0.1679 - \n",
      "16000/16000 [==============================] - 8s 470us/step\n",
      "4000/4000 [==============================] - 1s 260us/step\n",
      "Training DNN  17\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 647us/step - loss: 0.4326 - acc: 0.7975\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 159us/step - loss: 0.1789 - acc: 0.9339\n",
      "16000/16000 [==============================] - 7s 456us/step\n",
      "4000/4000 [==============================] - 1s 275us/step\n",
      "Training DNN  18\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 653us/step - loss: 0.4376 - acc: 0.7942\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 168us/step - loss: 0.1758 - acc: 0.9357\n",
      "16000/16000 [==============================] - 7s 446us/step\n",
      "4000/4000 [==============================] - 1s 241us/step\n",
      "Training DNN  19\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 640us/step - loss: 0.4374 - acc: 0.7976\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 151us/step - loss: 0.1821 - acc: 0.9313\n",
      "16000/16000 [==============================] - 7s 462us/step\n",
      "4000/4000 [==============================] - 1s 284us/step\n",
      "Training DNN  20\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 746us/step - loss: 0.4416 - acc: 0.7943\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 204us/step - loss: 0.1845 - acc: 0.9309\n",
      "16000/16000 [==============================] - 8s 508us/step\n",
      "4000/4000 [==============================] - 1s 233us/step\n",
      "Training DNN  21\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 737us/step - loss: 0.4463 - acc: 0.7954\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 208us/step - loss: 0.1831 - acc: 0.9298\n",
      "16000/16000 [==============================] - 8s 515us/step\n",
      "4000/4000 [==============================] - 1s 329us/step\n",
      "Training DNN  22\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 725us/step - loss: 0.4421 - acc: 0.7980\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 193us/step - loss: 0.1808 - acc: 0.9344\n",
      "16000/16000 [==============================] - 8s 503us/step\n",
      "4000/4000 [==============================] - 1s 275us/step\n",
      "Training DNN  23\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 746us/step - loss: 0.4352 - acc: 0.7974\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 160us/step - loss: 0.1824 - acc: 0.9330\n",
      "16000/16000 [==============================] - 7s 460us/step\n",
      "4000/4000 [==============================] - 1s 277us/step\n",
      "Training DNN  24\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 11s 668us/step - loss: 0.4343 - acc: 0.8021\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 148us/step - loss: 0.1846 - acc: 0.9296\n",
      "16000/16000 [==============================] - 7s 424us/step\n",
      "4000/4000 [==============================] - 1s 220us/step\n",
      "Training DNN  25\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 645us/step - loss: 0.4421 - acc: 0.7972\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 148us/step - loss: 0.1799 - acc: 0.9356\n",
      "16000/16000 [==============================] - 7s 426us/step\n",
      "4000/4000 [==============================] - 1s 222us/step\n",
      "Training DNN  26\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 10s 649us/step - loss: 0.4364 - acc: 0.7961\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 145us/step - loss: 0.1814 - acc: 0.9298\n",
      "16000/16000 [==============================] - 7s 431us/step\n",
      "4000/4000 [==============================] - 1s 222us/step\n",
      "Training DNN  27\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 11s 664us/step - loss: 0.4397 - acc: 0.7951\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 147us/step - loss: 0.1761 - acc: 0.9353\n",
      "16000/16000 [==============================] - 7s 437us/step\n",
      "4000/4000 [==============================] - 1s 235us/step\n",
      "Training DNN  28\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 11s 663us/step - loss: 0.4388 - acc: 0.7949\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 143us/step - loss: 0.1822 - acc: 0.9310\n",
      "16000/16000 [==============================] - 7s 431us/step\n",
      "4000/4000 [==============================] - 1s 220us/step\n",
      "Training DNN  29\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 11s 667us/step - loss: 0.4362 - acc: 0.8009\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 147us/step - loss: 0.1809 - acc: 0.9327\n",
      "16000/16000 [==============================] - 7s 435us/step\n",
      "4000/4000 [==============================] - 1s 224us/step\n",
      "Training DNN  30\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 11s 671us/step - loss: 0.4322 - acc: 0.7986\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 148us/step - loss: 0.1829 - acc: 0.9310\n",
      "16000/16000 [==============================] - 7s 445us/step\n",
      "4000/4000 [==============================] - 1s 237us/step\n",
      "Training DNN  31\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 11s 673us/step - loss: 0.4435 - acc: 0.7928\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 147us/step - loss: 0.1755 - acc: 0.9357\n",
      "16000/16000 [==============================] - 7s 445us/step\n",
      "4000/4000 [==============================] - 1s 228us/step\n",
      "Training DNN  32\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 11s 682us/step - loss: 0.4378 - acc: 0.7979\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 148us/step - loss: 0.1837 - acc: 0.9293\n",
      "16000/16000 [==============================] - 7s 455us/step\n",
      "4000/4000 [==============================] - 1s 230us/step\n",
      "Training DNN  33\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 11s 685us/step - loss: 0.4444 - acc: 0.7888\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 148us/step - loss: 0.1819 - acc: 0.9323\n",
      "16000/16000 [==============================] - 7s 459us/step\n",
      "4000/4000 [==============================] - 1s 292us/step\n",
      "Training DNN  34\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 13s 792us/step - loss: 0.4323 - acc: 0.7983\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 153us/step - loss: 0.1796 - acc: 0.9331\n",
      "16000/16000 [==============================] - 8s 489us/step\n",
      "4000/4000 [==============================] - 1s 258us/step\n",
      "Training DNN  35\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 752us/step - loss: 0.4356 - acc: 0.7968\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 134us/step - loss: 0.1793 - acc: 0.9312\n",
      "16000/16000 [==============================] - 7s 457us/step\n",
      "4000/4000 [==============================] - 1s 238us/step\n",
      "Training DNN  36\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.4328 - acc: 0.8011\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 4s 252us/step - loss: 0.1824 - acc: 0.9319 2s\n",
      "16000/16000 [==============================] - 8s 486us/step\n",
      "4000/4000 [==============================] - 1s 232us/step\n",
      "Training DNN  37\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 770us/step - loss: 0.4373 - acc: 0.7963\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 168us/step - loss: 0.1820 - acc: 0.9315\n",
      "16000/16000 [==============================] - 9s 555us/step\n",
      "4000/4000 [==============================] - 1s 308us/step\n",
      "Training DNN  38\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 748us/step - loss: 0.4408 - acc: 0.7923\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 181us/step - loss: 0.1729 - acc: 0.9366\n",
      "16000/16000 [==============================] - 8s 517us/step\n",
      "4000/4000 [==============================] - 1s 286us/step\n",
      "Training DNN  39\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 727us/step - loss: 0.4448 - acc: 0.7947\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 135us/step - loss: 0.1750 - acc: 0.9361\n",
      "16000/16000 [==============================] - 7s 449us/step\n",
      "4000/4000 [==============================] - 1s 217us/step\n",
      "Training DNN  40\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 741us/step - loss: 0.4434 - acc: 0.7937\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 181us/step - loss: 0.1724 - acc: 0.9353\n",
      "16000/16000 [==============================] - 8s 494us/step\n",
      "4000/4000 [==============================] - 1s 218us/step\n",
      "Training DNN  41\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 13s 810us/step - loss: 0.4493 - acc: 0.7946\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 205us/step - loss: 0.1731 - acc: 0.9371\n",
      "16000/16000 [==============================] - 8s 515us/step\n",
      "4000/4000 [==============================] - 1s 223us/step\n",
      "Training DNN  42\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 771us/step - loss: 0.4307 - acc: 0.7991\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 140us/step - loss: 0.1806 - acc: 0.9328\n",
      "16000/16000 [==============================] - 8s 497us/step\n",
      "4000/4000 [==============================] - 1s 213us/step\n",
      "Training DNN  43\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 725us/step - loss: 0.4413 - acc: 0.7923\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 137us/step - loss: 0.1753 - acc: 0.9364\n",
      "16000/16000 [==============================] - 7s 463us/step\n",
      "4000/4000 [==============================] - 1s 224us/step\n",
      "Training DNN  44\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 735us/step - loss: 0.4462 - acc: 0.7940\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 138us/step - loss: 0.1749 - acc: 0.9344\n",
      "16000/16000 [==============================] - 8s 479us/step\n",
      "4000/4000 [==============================] - 1s 234us/step\n",
      "Training DNN  45\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 729us/step - loss: 0.4436 - acc: 0.7951\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 140us/step - loss: 0.1835 - acc: 0.9308\n",
      "16000/16000 [==============================] - 8s 473us/step\n",
      "4000/4000 [==============================] - 1s 225us/step\n",
      "Training DNN  46\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 737us/step - loss: 0.4384 - acc: 0.7921\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 175us/step - loss: 0.1795 - acc: 0.9321\n",
      "16000/16000 [==============================] - 8s 495us/step\n",
      "4000/4000 [==============================] - 1s 222us/step\n",
      "Training DNN  47\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 14s 874us/step - loss: 0.4352 - acc: 0.7979\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 153us/step - loss: 0.1809 - acc: 0.9326\n",
      "16000/16000 [==============================] - 8s 507us/step\n",
      "4000/4000 [==============================] - 1s 235us/step\n",
      "Training DNN  48\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 12s 749us/step - loss: 0.4262 - acc: 0.8036\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 138us/step - loss: 0.1776 - acc: 0.9346\n",
      "16000/16000 [==============================] - 8s 483us/step\n",
      "4000/4000 [==============================] - 1s 242us/step\n",
      "Training DNN  49\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 12s 765us/step - loss: 0.4343 - acc: 0.7983\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 149us/step - loss: 0.1838 - acc: 0.9311\n",
      "16000/16000 [==============================] - 8s 490us/step\n",
      "4000/4000 [==============================] - 1s 247us/step\n"
     ]
    }
   ],
   "source": [
    "# Split the training data k-fold number of ways for k-fold validation of the learning algorithm\n",
    "k=5\n",
    "kf = sklearn.model_selection.KFold(n_splits=k)\n",
    "inds = [ind for ind in kf.split(x_tall, y_tall)\n",
    "train,val = inds[0]\n",
    "# Training and validation data for k fold cross validation\n",
    "Xtrain = x_uall[train]\n",
    "Ytrain = y_uall[train]\n",
    "Xval = x_uall[val]\n",
    "Yval = y_uall[val]\n",
    "\n",
    "# Specify number of Neural networks to train\n",
    "N_models = 10\n",
    "Predictions = []\n",
    "TrainErr = []\n",
    "TestErr = []\n",
    "\n",
    "# Define the DNN model\n",
    "for i in range(0,N_models):\n",
    "    print('Training DNN ',i)\n",
    "    model = getModel([500,250,125],0)\n",
    "    # Compile it and fit\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='RMSprop', metrics=['accuracy'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size=2**8, epochs=2)\n",
    "    # Store the models\n",
    "    TrainErr.append(model.evaluate(x=Xtrain, y=Ytrain))\n",
    "    TestErr.append(model.evaluate(x=Xval, y=Yval))\n",
    "    # Use weakly trained model to predict and store predictions\n",
    "    ypred = model.predict(Xval,batch_size=2**8)\n",
    "    Predictions.append(ypred)\n",
    "\n",
    "Predictions = np.array(Predictions)\n",
    "TrainErr = np.array(TrainErr)\n",
    "TestErr = np.array(TestErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples where stdev > 0,  2119\n",
      "Final accuracy of random forest =  0.86\n"
     ]
    }
   ],
   "source": [
    "ypred = []\n",
    "for i in Predictions:\n",
    "    ypred.append(Unencode(i).astype(int))\n",
    "\n",
    "# Get mean and standard deviation of samples\n",
    "ypmean=np.mean(ypred,axis=0)\n",
    "std=np.std(ypred,axis=0)\n",
    "\n",
    "print('Number of samples where stdev > 0, ',np.sum(std>0))\n",
    "ypred = (ypmean > 0.5).astype(int)\n",
    "ytrue = Unencode(Yval).astype(int)\n",
    "\n",
    "acc = 1.0*np.sum(ypred == ytrue)/len(ytrue)\n",
    "print('Final accuracy of random forest = ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random neuron forest\n",
    "def getDNNForestCross(k,N_models,x_tall,y_tall):\n",
    "    # Storage for k fold cross validation\n",
    "    facc = []\n",
    "    \n",
    "    # Split the training data k-fold number of ways for k-fold validation of the learning algorithm\n",
    "    k=5\n",
    "    kf = sklearn.model_selection.KFold(n_splits=k)\n",
    "    inds = [ind for ind in kf.split(x_tall, y_tall)]\n",
    "\n",
    "    j=0\n",
    "    for train,val in inds:\n",
    "        print('Cross fold validation ',j,'/',k)\n",
    "        # Training and validation data for k fold cross validation\n",
    "        Xtrain = x_tall[train]\n",
    "        Ytrain = y_tall[train]\n",
    "        Xval = x_tall[val]\n",
    "        Yval = y_tall[val]\n",
    "\n",
    "        # Store predictions from each tree in DNN forest\n",
    "        Predictions = []\n",
    "        \n",
    "        # Define the DNN model\n",
    "        for i in range(0,N_models):\n",
    "            print('Training DNN ',i)\n",
    "            model = getModel([500,250,125],0)\n",
    "            # Compile it and fit\n",
    "            model.compile(loss='categorical_crossentropy',optimizer='RMSprop', metrics=['accuracy'])\n",
    "            model.fit(Xtrain, Ytrain, batch_size=2**8, epochs=2,verbose=1)\n",
    "\n",
    "            # Use weakly trained model to predict and store predictions\n",
    "            ypred = model.predict(Xval,batch_size=2**8,verbose=1)\n",
    "            Predictions.append(ypred)\n",
    "\n",
    "        Predictions = np.array(Predictions)\n",
    "        \n",
    "        ypred = []\n",
    "        for i in Predictions:\n",
    "            ypred.append(Unencode(i).astype(int))\n",
    "\n",
    "        # Get mean and standard deviation of samples\n",
    "        ypmean=np.mean(ypred,axis=0)\n",
    "        std=np.std(ypred,axis=0)\n",
    "        print('Number of samples where stdev > 0, ',np.sum(std>0))\n",
    "        \n",
    "        # Compute accuracy of predictions\n",
    "        ypred = (ypmean > 0.5).astype(int)\n",
    "        ytrue = Unencode(Yval).astype(int)\n",
    "        acc = 1.0*np.sum(ypred == ytrue)/len(ytrue)\n",
    "        print('Final accuracy of random forest = ',acc)\n",
    "        j=j+1\n",
    "        \n",
    "        facc.append(acc)\n",
    "        \n",
    "    print('avg Accuracy of all random forests',np.mean(facc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross fold validation  0 / 5\n",
      "Training DNN  0\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 13s 797us/step - loss: 0.4342 - acc: 0.8000\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 154us/step - loss: 0.1825 - acc: 0.9311\n",
      "4000/4000 [==============================] - 5s 1ms/step\n",
      "Training DNN  1\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 14s 844us/step - loss: 0.4393 - acc: 0.7969\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 181us/step - loss: 0.1899 - acc: 0.9297\n",
      "4000/4000 [==============================] - 5s 1ms/step\n",
      "Training DNN  2\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 13s 813us/step - loss: 0.4315 - acc: 0.8037\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 197us/step - loss: 0.1785 - acc: 0.9337\n",
      "4000/4000 [==============================] - 5s 1ms/step\n",
      "Training DNN  3\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 14s 849us/step - loss: 0.4482 - acc: 0.7908\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 161us/step - loss: 0.1801 - acc: 0.9327\n",
      "4000/4000 [==============================] - 5s 1ms/step\n",
      "Training DNN  4\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 914us/step - loss: 0.4264 - acc: 0.8039\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 167us/step - loss: 0.1872 - acc: 0.9296\n",
      "4000/4000 [==============================] - 6s 1ms/step\n",
      "Training DNN  5\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 14s 868us/step - loss: 0.4354 - acc: 0.8004\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 159us/step - loss: 0.1803 - acc: 0.9325\n",
      "4000/4000 [==============================] - 5s 1ms/step\n",
      "Training DNN  6\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 14s 901us/step - loss: 0.4466 - acc: 0.7948\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 165us/step - loss: 0.1833 - acc: 0.9324 1s - los\n",
      "4000/4000 [==============================] - 5s 1ms/step\n",
      "Training DNN  7\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 14s 877us/step - loss: 0.4276 - acc: 0.8001\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 193us/step - loss: 0.1797 - acc: 0.9323\n",
      "4000/4000 [==============================] - 6s 1ms/step\n",
      "Training DNN  8\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 926us/step - loss: 0.4320 - acc: 0.8007\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 168us/step - loss: 0.1847 - acc: 0.9292\n",
      "4000/4000 [==============================] - 5s 1ms/step\n",
      "Training DNN  9\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 918us/step - loss: 0.4365 - acc: 0.7991\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 160us/step - loss: 0.1814 - acc: 0.9316\n",
      "4000/4000 [==============================] - 5s 1ms/step\n",
      "Number of samples where stdev > 0,  1412\n",
      "Final accuracy of random forest =  0.85875\n",
      "Cross fold validation  1 / 5\n",
      "Training DNN  0\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 953us/step - loss: 0.4319 - acc: 0.8009\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 170us/step - loss: 0.1727 - acc: 0.9356\n",
      "4000/4000 [==============================] - 6s 1ms/step\n",
      "Training DNN  1\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 14s 895us/step - loss: 0.4277 - acc: 0.8003\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 2s 155us/step - loss: 0.1778 - acc: 0.9345\n",
      "4000/4000 [==============================] - 6s 1ms/step\n",
      "Training DNN  2\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 956us/step - loss: 0.4280 - acc: 0.7999\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 178us/step - loss: 0.1737 - acc: 0.9371\n",
      "4000/4000 [==============================] - 5s 1ms/step\n",
      "Training DNN  3\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 16s 974us/step - loss: 0.4380 - acc: 0.7984\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 179us/step - loss: 0.1732 - acc: 0.9376\n",
      "4000/4000 [==============================] - 5s 1ms/step\n",
      "Training DNN  4\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 926us/step - loss: 0.4274 - acc: 0.8024\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 174us/step - loss: 0.1778 - acc: 0.9344\n",
      "4000/4000 [==============================] - 6s 2ms/step\n",
      "Training DNN  5\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 942us/step - loss: 0.4268 - acc: 0.8018\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 181us/step - loss: 0.1781 - acc: 0.9345\n",
      "4000/4000 [==============================] - 6s 1ms/step\n",
      "Training DNN  6\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 954us/step - loss: 0.4271 - acc: 0.8026\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 183us/step - loss: 0.1814 - acc: 0.9299\n",
      "4000/4000 [==============================] - 6s 1ms/step\n",
      "Training DNN  7\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 922us/step - loss: 0.4383 - acc: 0.7955\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 157us/step - loss: 0.1805 - acc: 0.9323\n",
      "4000/4000 [==============================] - 5s 1ms/step\n",
      "Training DNN  8\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 16s 985us/step - loss: 0.4259 - acc: 0.8011\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 203us/step - loss: 0.1843 - acc: 0.9308\n",
      "4000/4000 [==============================] - 6s 1ms/step\n",
      "Training DNN  9\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 933us/step - loss: 0.4337 - acc: 0.8018\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 214us/step - loss: 0.1791 - acc: 0.9334\n",
      "4000/4000 [==============================] - 6s 1ms/step\n",
      "Number of samples where stdev > 0,  1477\n",
      "Final accuracy of random forest =  0.8565\n",
      "Cross fold validation  2 / 5\n",
      "Training DNN  0\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 943us/step - loss: 0.4328 - acc: 0.7986\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 176us/step - loss: 0.1779 - acc: 0.9344\n",
      "4000/4000 [==============================] - 6s 1ms/step\n",
      "Training DNN  1\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 916us/step - loss: 0.4273 - acc: 0.8040\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 172us/step - loss: 0.1764 - acc: 0.9368\n",
      "4000/4000 [==============================] - 5s 1ms/step\n",
      "Training DNN  2\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 926us/step - loss: 0.4320 - acc: 0.8034\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 174us/step - loss: 0.1699 - acc: 0.9351\n",
      "4000/4000 [==============================] - 6s 1ms/step\n",
      "Training DNN  3\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.4280 - acc: 0.8054\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 215us/step - loss: 0.1779 - acc: 0.9364\n",
      "4000/4000 [==============================] - 6s 1ms/step\n",
      "Training DNN  4\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 15s 949us/step - loss: 0.4283 - acc: 0.8006\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 3s 165us/step - loss: 0.1789 - acc: 0.9339\n",
      "4000/4000 [==============================] - 6s 1ms/step\n",
      "Training DNN  5\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "getDNNForestCross(5,10,x_tall,y_tall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output final predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of Neural networks to train\n",
    "N_models = 20\n",
    "Predictions = []\n",
    "\n",
    "# Define the DNN model\n",
    "for i in range(0,N_models):\n",
    "    print('Training DNN ',i)\n",
    "    model = getModel([500,250,125],0)\n",
    "    # Compile it and fit\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='RMSprop', metrics=['accuracy'])\n",
    "    model.fit(x_uall, y_uall, batch_size=2**8, epochs=2)\n",
    "    # Use weakly trained model to predict and store predictions\n",
    "    ypred = model.predict(FV_data,batch_size=2**8)\n",
    "    Predictions.append(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = np.array(Predictions)\n",
    "\n",
    "ypred = []\n",
    "for i in Predictions:\n",
    "    ypred.append(Unencode(i).astype(int))\n",
    "\n",
    "# Get mean and standard deviation of samples\n",
    "ypmean=np.mean(ypred,axis=0)\n",
    "std=np.std(ypred,axis=0)\n",
    "print('Number of samples where stdev > 0, ',np.sum(std>0))\n",
    "\n",
    "# Compute final predictions and output it\n",
    "ypred = (ypmean > 0.5).astype(int)\n",
    "writeResults(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "import keras.regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, GaussianNoise, GaussianDropout, LeakyReLU\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final validation data set\n",
    "FV_data = np.loadtxt('../data/test_data.txt',delimiter=' ',skiprows=1)\n",
    "# Load input training data set\n",
    "train_data = np.loadtxt('../data/training_data.txt',delimiter=' ',skiprows=1)\n",
    "\n",
    "# Split y_train and x_train from training set\n",
    "X_Tall = train_data[:,1:]\n",
    "y_Tall = train_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5)\n",
    "inds = list(kf.split(X_Tall, y_Tall))\n",
    "\n",
    "train_idx, val_idx = inds[4]\n",
    "\n",
    "X_train, y_train = X_Tall[train_idx], y_Tall[train_idx] \n",
    "X_val, y_val = X_Tall[val_idx], y_Tall[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate DNN of given depth and width\n",
    "def create_model(layers,Pdrop):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layers[0],input_shape=(1000,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    for i in layers[1:]:\n",
    "        model.add(Dense(i))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.3))\n",
    "        model.add(Dropout(Pdrop))\n",
    "    \n",
    "    # predicting probabilities of each of the 2 classes\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',optimizer='RMSprop', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "neural = KerasClassifier(build_fn=create_model, layers=[500,250,125,75,25], Pdrop=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16001 samples, validate on 3999 samples\n",
      "Epoch 1/6\n",
      "16001/16001 [==============================] - 4s 269us/step - loss: 0.5028 - acc: 0.7619 - val_loss: 0.3809 - val_acc: 0.8452\n",
      "Epoch 2/6\n",
      "16001/16001 [==============================] - 2s 116us/step - loss: 0.3514 - acc: 0.8507 - val_loss: 0.4069 - val_acc: 0.8520\n",
      "Epoch 3/6\n",
      "16001/16001 [==============================] - 2s 119us/step - loss: 0.3157 - acc: 0.8693 - val_loss: 0.4102 - val_acc: 0.8512\n",
      "Epoch 4/6\n",
      "16001/16001 [==============================] - 2s 119us/step - loss: 0.2897 - acc: 0.8812 - val_loss: 0.4344 - val_acc: 0.8470\n",
      "Epoch 5/6\n",
      "16001/16001 [==============================] - 2s 118us/step - loss: 0.2631 - acc: 0.8908 - val_loss: 0.4488 - val_acc: 0.8520\n",
      "Epoch 6/6\n",
      "16001/16001 [==============================] - 2s 119us/step - loss: 0.2387 - acc: 0.9034 - val_loss: 0.4300 - val_acc: 0.8482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26459297f98>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural.fit(X_train, y_train, batch_size=2**8, epochs=6, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9120054996562715\n",
      "0.8549637409352339\n"
     ]
    }
   ],
   "source": [
    "svm = make_pipeline(StandardScaler(), SVC(C=4.0, gamma=0.0002))\n",
    "svm.fit(X_train, y_train)\n",
    "print(svm.score(X_train, y_train))\n",
    "print(svm.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8669458158865071\n",
      "0.8402100525131283\n"
     ]
    }
   ],
   "source": [
    "ada = make_pipeline(StandardScaler(),\n",
    "                     AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), \n",
    "                                        n_estimators=500,\n",
    "                                        learning_rate=1))\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    "print(ada.score(X_train, y_train))\n",
    "print(ada.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nn = neural.predict(X_val)\n",
    "pred_svm = svm.predict(X_val)\n",
    "pred_ada = ada.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8534633658414603"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_comb = np.zeros(len(y_val))\n",
    "for i in range(len(y_val)):\n",
    "    votes = [pred_nn[i][0], pred_svm[i], pred_ada[i]]\n",
    "    ones= votes.count(1)\n",
    "    if ones >= 2:\n",
    "        pred_comb[i] = 1\n",
    "    else:\n",
    "        pred_comb[i] = 0\n",
    "        \n",
    "accuracy_score(pred_comb, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Val for first  fold: 0.8557860534866284\n",
    "# Val for second fold: 0.8512871782054486\n",
    "# Val for third  fold: 0.843\n",
    "# Val for fourth fold: 0.8472118029507377\n",
    "# Val for fifth  fold: 0.8534633658414603\n",
    "# Average: 0.850"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
